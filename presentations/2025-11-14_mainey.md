## # Using simulation to evaluate a service: what to do when you've got no data, no clear questions, and no clue if it's working (Chris Mainey)

### Links

- [Slides](https://chrismainey.github.io/NHS_R_2025_simulating/NHS_R_presentation.html#/title-slide)

- [Code](https://github.com/chrismainey/NHS_R_2025_simulating)


### Abstract

It seems common for the NHS to build service without rigorous impact modelling, well-calibrated evaluation/success criteria, or prospective data collection to judge progress.  Analytical teams are often brought in once a service is running and asked to evaluate whether it is working without contributing to design.  During this talk, I will discusses our approach to such a problem in our health economy, where a service with unclear boundaries and operating model, and without service-specific data, was making implausible claims about the benefits.  Our only option was to calculate what success might look like (a "counterfactual"), based on prior data and some assumptions, and then simulate this forward to recent time periods.  This approach helped us quantify whether the claimed benefits are possible, and what would be required to meet the claimed benefits.  Our approach included framing the question, turning this into a simulation, sourcing data for calibration, quantifying the uncertainty with Monte Carlo methods, and applying it to our local situation using R and Quarto.